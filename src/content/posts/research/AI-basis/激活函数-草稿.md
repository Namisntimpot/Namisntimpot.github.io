---
title: 激活函数
published: 2023-07-15
description: 对激活函数的一些总结...可能直接上网找类似的总结更好...
tags: [research, 深度学习基础]
category: 科研
draft: true
---

## Sigmoid  
$$  
y = \frac{1}{1+e^{-x}}  
$$  
## ReLU  
$$  
\begin{aligned}  
y =  
\begin{cases}  
x, x>=0 \\  
0, else  
\end{cases}  
\end{aligned}  
$$  
  
## ELU  
$$  
\begin{aligned}  
y =  
\begin{cases}  
x, x>=0 \\  
e^x-1, else  
\end{cases}  
\end{aligned}  
$$  
+ 所有点连续、可微  
+ 收敛更快  
+ 没有梯度消失/爆炸  
+ 准确性更高  
  
